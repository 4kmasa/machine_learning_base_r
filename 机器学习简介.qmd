---
title: "机器学习简介"
---

## 概念简介

机器学习是一个很宽泛的概念，但是从机器学习在医学中的使用（尤其是在发文章这块）情况来看，它只是作为一个能够根据多个指标给出预测结果的数学方法而已，并不是什么高大上的概念。

举个简单的例子说明。

学过《医学统计学》的肯定都知道多元线性回归和逻辑回归，这两种方法在医学统计中都是用来探索危险因素的，比如：探索身高、体重、血脂、饮食情况等对血糖有没有影响？这时我们会根据因变量的类型选择合适的方法，然后建立回归方程，看看各个变量的P值等。

这就是典型的机器学习方法在医学中的使用，多元线性回归和逻辑回归也属于机器学习方法，只不过当我们在医学统计的范围中使用时，我们更加关注的是各个自变量到底有没有意义（也就是P值），当在机器学习的范围中使用这些方法时，我们会更偏向于使用多个自变量**预测**因变量的值。比如根据患者的身高、体重、血脂、饮食情况等，预测患者是否会得糖尿病。此时我们依然是建立回归方程，只不过目的变了。

线性回归、逻辑回顾、cox回归是我们见到的最多的方法，因为临床中用的非常多，这些不仅是统计方法，也是机器学习方法，除此之外，大家常见到的其他机器学习方法还有：决策树、随机森林、K最近邻、支持向量机等。使用它们的目的都是为了预测结果，比如：预测患者的生死、预测是否会得某种疾病、预测肿瘤是良性还是恶性、预测患者是出血还是血栓、预测患者的出血风险、流产风险等。

具体使用时的步骤也是差不多的，都是要根据数据选择合适的方法，然后建立模型，然后进行预测。机器学习并不神秘，我们只是把它当做是**一种预测结果的工具**而已，不需要理解背后复杂的数学原理，只需要会用即可。

那么机器学习到底怎么学习的呢？难道是像人类一样能用脑子思考吗？并不是。比如你要用患者的身高、体重、血脂、饮食习惯，预测患者的餐后2h血糖值，那么这4个自变量和因变量之间肯定是存在某种关系，才能让我们去探索，去预测。可能是“血脂越高则血糖越高”这种正相关或者负相关的关系，也可能是在某个区间内增加然后在某个区间内下降这种不单调的关系、甚至是其他类型更加复杂的关系。

机器学习方法，就可以识别这种数据内部的关系，或者叫规律，或者叫模式（pattern）。不同的机器学习方法能够识别不同的关系模式。比如对于正相关或者负相关这种关系，线性回归就很擅长，因为它拟合出来就是一条线，完美的线性关系。而且当它根据当前的数据识别出这种关系后，你再给它新的数据，它可以根据识别出的关系，对新的数据作出预测。

所以“机器学习”这4个字并不是说机器能够像人类一样自思考，只是一个比喻，用来说明不同的算法能够识别出数据间的模式，还能够根据识别出来的模式，对新的数据作出预测。

## 回归和分类

根据因变量的数据类型，我们使用机器学习的目的主要可以分为两类：

1. 回归：因变量是数值型，比如血压、血脂、血糖，我们要预测的是具体的数值
2. 分类：因变量是分类型，比如是/否，患病/不患病，良性/恶性，生存/死亡，我们要把结果归到某一个类别中，而不是预测数值

机器学习最主要目的就是回归和分类，当然除了回归和分类，还有聚类分析和主成分分析这种，也属于机器学习方法。大多数模型都是既支持分类又支持回归的，比如：随机森林、支持向量机等，还有些也支持聚类、异常值检测等，但是有些算法可能只支持一种类型，比如：线性回归只支持回归任务。

除了这些，医学中还有一块非常重要的内容：生存分析，比如cox生存分析。在传统的机器学习领域，这块内容很少涉及，但是近几年支持生存分析的机器学习算法越来越多了，比如随机生存森林、生存支持向量机、生存提升树模型、deepsurv等，这方面的发展也越来越快。

## 有监督和无监督

线性回归、随机森林等这种方法，在使用时是需要数据中有因变量的，使用的数据中有因变量的就是**有监督学习方法**（supervised learning）；常见的方法都是有监督学习方法，比如：

- 线性回归
- 逻辑回归
- lasso回归
- 决策树
- 随机森林
- KNN
- 支持向量机
- 各种提升模型
- ...

像聚类分析、主成分分析这种，使用的数据中没有因变量的，被称为**无监督学习方法**（unsupervised learning）。

## 一些术语

- 因变量：应变量、结果变量（outcome）、标签（label）
- 自变量：预测变量（predictor）、特征（feature）、协变量（注意上下文）

## 一般流程

机器学习在医学中使用的一般流程是什么样的呢？

首先**第一步是准备数据**，你得有数据才能进行接下来的一切。

医学中遇到的数据一般都是很乱的，不能直接用，不管你是从临床中收集的还是白嫖的各种数据库资源，都是不能直接用的。所以我们要对这些数据进行整理，把这些数据变成算法能够使用的样子，这个过程叫做**数据清洗**（data cleaning）。

数据清洗其实是最重要的一步！只有把数据整理成合适的格式，才能让模型充分识别数据内部的关系。你自己要对自己的数据有一个基本的理解，比如：

- 你的数据是什么类型的？
- 有哪些行哪些列？每行每列都是什么意思？
- 是数值型还是类别型？
- 有没有缺失值？
- 是不是偏态分布？
- 有没有极端值？
- 需不需要进行转换？
- 你的建模目的是什么？
- 你希望本次建模能达到什么样的目标？
- ...

这些问题都是最基础的问题，如果你自己都不清楚，别指望结果会很好！

在进行数据清洗的过程中，除了对数据进行整理外，还不断的借助图形来展示结果，通常这一过程会持续重复多次。在建模之前的这种数据清洗和可视化的过程，被称为**探索性数据分析**（exploratory data analysis，EDA）

数据整理好之后，第二步才是**建立模型**。这一步并不是简单地拟合模型，而是包括了模型拟合、模型评价、模型调优、变量选择等多个步骤。这一步是机器学习的核心。也是我们要详细介绍的部分。

最后一步就是整理结果，把报告呈现出来。


