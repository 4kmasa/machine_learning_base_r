---
title: "变量选择"
---

变量选择是机器学习中很重要的内容，但不是本合集的主要内容，所以以下简单介绍下，感兴趣的可以参考[变量选择方法合集](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUzOTQzNzU0NA==&action=getalbum&album_id=3157267091889225730&scene=173&subscene=&sessionid=svr_2a789493086&enterid=1714216072&from_msgid=2247496541&from_itemidx=1&count=3&nolastread=1#wechat_redirect)

## 常见方法简介

变量选择(特征选择,feature-selection)，是机器学习领域非常重要的问题，到底哪些变量是有用的，哪些是不重要的，可以删除的，怎么选才能提高模型表现，理论非常复杂，实在不是一个临床医生能完全掌握的，以下简单介绍下.

在传统的临床预测模型中，比较常见的变量筛选方法有：

- 先单因素后多因素
- 最优子集（全子集回归）
- 逐步选择法
- lasso回归筛选变量
- 随机森林筛选变量
- ...

本文介绍的机器学习中的变量筛选方法（并没有包含在本书中，可在公众号**医学和生信笔记**后台回复**变量筛选**获取相关合集）虽然可以用在临床预测模型中，但是和大家常见的“先单因素后多因素”这种完全不是一个概念，虽然它们的目的相同，都是为了提高模型表现。

当数据的维度增加时，决定模型最终使用哪些预测变量是很关键的问题。数据的维度就是自变量(预测变量)

特征选择是特征工程中非常重要的一部分内容，特征选择的方法非常多，主要可以分为以下3类，每个大类下又会细分为好多具体的方法，有机会慢慢介绍...

- **过滤法(filter)**
  - 缺失值比例、方差、相关系数、方差分析/t检验/卡方检验、ROC等
  - 信息增益 information gain
  - 最小冗余最大相关性mrmr，Minimum Redundancy Maximum Relevance
  - ...
- **包装法(wrapper)**
  - 向前、向后、逐步
  - 递归特征消除rfe(也属于向后)
  - 模拟退火
  - 遗传算法
  - ...
- **嵌入法(embeded)**
  - 随机森林
  - MARS
  - lasso
  - GBDT
  - ...

大家经常使用的逐步选择法(step/stepAIC)，也属于包装法的一种，在之前的推文中已有介绍：[R语言逻辑回归的细节解读](https://mp.weixin.qq.com/s/3A8ZiegbsQRjOSw2T3jldg)，但是并不局限于逻辑回归。

3种方法的简单解释如下，以后单独演示时会专门再解释：

- 过滤法：进行变量选择时不考虑模型表现和变量重要性等，只是通过变量自身的情况、变量间的关系进行选择。
- 包装法：变量选择考虑到了模型表现和变量重要性等信息，属于是对每一个模型进行“量身定制”的变量
- 嵌入法：变量选择的过程就在模型训练的过程之中

## R语言中的实现

后续主要介绍3个包：`caret`、`mlr3`、`tidymodels`

在`caret`包中主要可以实现**包装法和过滤法**。

`caret`包中的封装法有递归特征消除(recursive feature elimination，rfe)算法，遗传算法（genetic algorithms，ga）和模拟退火（Simulated annealing，sa）算法。

过滤法通过`sbf`函数实现，但其实部分数据预处理方法属于过滤法的内容。

目前`mlr3`已经实现了对这3种方法的支持，可以说是R语言中对变量筛选做的最好的综合性R包了。

过滤法和嵌入法通过`mlr3filters`包实现，包装法通过`mlr3fselect`包实现，关于这两种方法的具体实现，早已在之前的推文介绍过，大家可以参考之前的推文[mlr3特征选择](https://mp.weixin.qq.com/s/rcK4iMBm6rzclhoScPWTMA)

不过随着`mlr3`的更新，部分细节稍有不同，以后再给大家慢慢演示。

`tidymodels`中的特征选择很不完善，不如`mlr3`做得好，也不如`caret`做得好！

部分过滤法包含在`recipes`中，部分包装法和嵌入法现在并不成熟，没有完整的实现，部分可通过`colina`包实现，但是这个包并不属于`tidymodels`，而是个人开发者贡献的R包。

已经看到`tidymodels`的开发者有计划增加特征选择的这部分特性，但不知何时实现...

